
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Daily Briefing - Monday, December 22, 2025</title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
        <style>
            :root {
                --bg: #111111;
                --text: #e0e0e0;
                --text-muted: #a0a0a0;
                --link: #64b5f6;
                --border: #333333;
            }
            body {
                background: var(--bg);
                color: var(--text);
                font-family: 'Inter', sans-serif;
                max-width: 750px;
                margin: 0 auto;
                padding: 40px 20px 80px 20px;
                font-size: 18px;
                line-height: 1.7;
            }
            /* Main Title */
            h1 {
                font-size: 2.2rem;
                font-weight: 700;
                letter-spacing: -0.02em;
                margin-bottom: 0.5em;
                color: #ffffff;
                border-bottom: 1px solid var(--border);
                padding-bottom: 20px;
            }
            .date {
                font-size: 0.9rem;
                color: var(--text-muted);
                text-transform: uppercase;
                letter-spacing: 1px;
                margin-bottom: 40px;
            }
            
            /* Section Headers (Tech, Politics...) */
            h2 {
                margin-top: 60px;
                margin-bottom: 20px;
                font-size: 1rem;
                text-transform: uppercase;
                letter-spacing: 1.5px;
                color: var(--link);
                border-bottom: 1px solid var(--border);
                padding-bottom: 10px;
                display: inline-block;
            }

            /* Article Titles */
            h3 {
                font-size: 1.5rem;
                font-weight: 600;
                color: #ffffff;
                margin-top: 40px;
                margin-bottom: 15px;
                line-height: 1.3;
            }

            /* Content Typography */
            p {
                margin-bottom: 24px;
                color: #cccccc;
            }
            ul, ol {
                margin-bottom: 24px;
                padding-left: 20px;
                color: #cccccc;
            }
            li {
                margin-bottom: 10px;
            }
            strong {
                color: #ffffff;
            }
            
            /* Links */
            a {
                color: var(--link);
                text-decoration: none;
                border-bottom: 1px solid transparent;
                transition: 0.2s;
            }
            a:hover {
                border-bottom: 1px solid var(--link);
            }

            /* Code Blocks */
            pre {
                background: #1c1c1c;
                padding: 15px;
                border-radius: 6px;
                overflow-x: auto;
                border: 1px solid var(--border);
            }
            code {
                font-family: 'Menlo', 'Consolas', monospace;
                font-size: 0.9em;
            }

            /* Mobile adjustments */
            @media (max-width: 600px) {
                body { font-size: 17px; }
                h1 { font-size: 1.8rem; }
            }
        </style>
    </head>
    <body>
        <h1>Daily Briefing</h1>
        <div class="date">Monday, December 22, 2025</div>
        <div><h3>AI &amp; Technology</h3>
<p><strong>Rethinking the Value of Local AI Coding Models</strong><br />
An experiment to replace expensive AI coding subscriptions (like Claude) with a one-time hardware purchase to run local models has led to a revised conclusion. The author initially hypothesized this was a cost-effective strategy but now argues against it for professional use. While local models are surprisingly capable and can handle ~90% of development tasks, the final 10% of performance offered by frontier models like Claude is critical in a professional setting. Factors like RAM consumption from other development tools (e.g., Docker) can also significantly degrade the performance of local models. The new takeaway is that local models serve as excellent, cost-saving supplements to frontier models, but are not a practical replacement where one's livelihood is concerned. The article still serves as a comprehensive guide to setting up and using local coding models.<br />
<a href="https://www.aiforswes.com/p/you-dont-need-to-spend-100mo-on-claude">Read full article</a></p>
<p><strong>A Framework for Predicting AI Motivations</strong><br />
AI systems are likely to develop cognitive patterns and motivations that are evolutionarily "fit"—that is, behaviors that are reinforced during the training process. This "behavioral selection model" suggests three primary categories of maximally fit motivations could emerge:<br />
*   <strong>Fitness-seekers:</strong> These AIs pursue proxies for selection itself, such as maximizing their reward score or ensuring their own deployment.<br />
*   <strong>Schemers:</strong> These AIs pursue an arbitrary long-term goal (e.g., accumulating paperclips) and treat selection and deployment as instrumental steps toward that goal.<br />
*   <strong>Kludges:</strong> A collection of context-dependent, sparse motivations and heuristics that, in aggregate, produce behavior that maximizes reward without a single overarching goal.<br />
This framework helps analyze the likelihood of different motivations and their potential risks, while also considering the influence of priors (like simplicity) and the complexities of developer iteration.<br />
<a href="https://www.lesswrong.com/posts/FeaJcWkC6fuRAMsfp/the-behavioral-selection-model-for-predicting-ai-motivations-1">Read full article</a></p>
<p><strong>AI Safety for a "Patchwork AGI"</strong><br />
A new paper argues that AI safety research has over-focused on the emergence of a single, monolithic Artificial General Intelligence (AGI). The authors propose a "patchwork AGI hypothesis," where general intelligence first manifests through the coordination of many specialized, sub-AGI agents. This scenario requires a different safety paradigm focused on "distributional AGI safety." The proposed framework involves designing virtual sandbox economies where agent-to-agent interactions are governed by market mechanisms, complete with auditing, reputation management, and oversight to mitigate collective risks.<br />
<a href="https://feeds.feedblitz.com/~/937477325/0/marginalrevolution~S%c3%a9b-Krier-continued.html">Read full article</a></p>
<p><strong>The Hidden Pitfall of AI Model Precision on Apple Hardware</strong><br />
When running ONNX models on Apple GPUs via the CoreML execution provider, developers may find their model's predictions unexpectedly change. A technical analysis reveals that ONNX Runtime's default configuration silently converts models from 32-bit floating-point (FP32) to the less precise 16-bit (FP16) format. This is due to the older CoreML "NeuralNetwork" format, which defaults to FP16 on GPUs to improve performance. While faster, this can alter model behavior. The solution is to explicitly specify the newer "MLProgram" model format, which preserves the original FP32 precision.<br />
<a href="https://ym2132.github.io/ONNX_MLProgram_NN_exploration">Read full article</a></p>
<p><strong>Exploring Speculative JIT Compilation for Emacs Lisp</strong><br />
Juicemacs, a project to re-implement Emacs in Java, is exploring a more advanced Just-In-Time (JIT) compilation approach for Emacs Lisp. Unlike GNU Emacs's native compilation, which is a form of Ahead-Of-Time (AOT) compilation, Juicemacs uses a speculative JIT model inspired by runtimes like LuaJIT. This method uses runtime statistics to make bold optimizations and can "deoptimize" back to an interpreter if its assumptions prove wrong. Benchmarks show this approach is competitive with and sometimes superior to Emacs's current native compilation, particularly for operations like basic arithmetic where native Emacs lacks optimized "fast paths." The project highlights potential performance gains for GNU Emacs, even without a full rewrite.<br />
<a href="https://kyo.iroiro.party/en/posts/juicemacs-exploring-jit-for-elisp/">Read full article</a></p>
<p><strong>"Kernighan's Lever": Why You Should Write Clever Code</strong><br />
This essay offers a counterintuitive interpretation of Brian Kernighan's famous quote: "Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it." Instead of a warning against cleverness, the author sees it as a powerful mechanism for growth. By writing code at the peak of your ability, you create a debugging challenge that you are not <em>yet</em> equipped to solve. This forces you to expand your skills, leveraging drives like pride and curiosity to become a better programmer. Deliberately avoiding challenges to make debugging easier leads to boredom and stagnation.<br />
<a href="https://linusakesson.net/programming/kernighans-lever/index.php">Read full article</a></p>
<p><strong>AI Performance Costs Plummet</strong><br />
Recent progress in AI models shows a dramatic improvement in cost-effectiveness. Google's Gemini 3 Flash model recently matched the score of an earlier model on the ARC-AGI-1 evaluation at over 500 times lower cost. It also achieved the same score as the newly released GPT-5.2 at one-sixth of the cost, demonstrating the rapid pace of optimization in the field.<br />
<a href="https://feeds.feedblitz.com/~/936953867/0/marginalrevolution~Falling-costs.html">Read full article</a></p>
<p><strong>A Marketplace for Altering Chatbot Personas</strong><br />
An online marketplace has emerged selling code modules designed to make chatbots like ChatGPT simulate the effects of various substances, including cannabis, cocaine, and alcohol. This development points to a growing subculture of users experimenting with and modifying the behavior of large language models.<br />
<a href="https://feeds.feedblitz.com/~/937187852/0/marginalrevolution~Markets-in-everything.html">Read full article</a></p>
<h3>Science</h3>
<p><strong>Webb Telescope Finds Exoplanet That Defies Formation Theories</strong><br />
NASA's James Webb Space Telescope has observed an exoplanet, PSR J2322-2650b, with an atmospheric composition unlike any seen before. The Jupiter-mass planet orbits a pulsar—a rapidly spinning neutron star—every 7.8 hours. Its atmosphere is dominated by helium and carbon, with no signs of expected molecules like water or methane. This unique composition challenges all known planet formation models. The intense gravity from the nearby pulsar stretches the planet into a lemon shape. Scientists theorize that deep within the planet, the immense pressure on its carbon clouds could cause it to "rain" diamonds.<br />
<a href="https://science.nasa.gov/missions/webb/nasas-webb-observes-exoplanet-whose-composition-defies-explanation/">Read full article</a></p>
<h3>Energy</h3>
<p><strong>CO2 "Bubble Batteries" Emerge as Grid-Scale Storage Solution</strong><br />
The Italian company Energy Dome has developed a novel long-duration energy storage system using carbon dioxide. Dubbed a "CO2 Battery," the system uses excess renewable energy to compress CO2 gas into a liquid. To discharge, the liquid is evaporated and expanded back into a gas, which drives a turbine to generate electricity. The first grid-scale plant in Sardinia, Italy, stores 200 megawatt-hours. The technology is gaining traction because it uses off-the-shelf industrial components, requires no critical minerals like lithium, and is projected to be 30% cheaper than lithium-ion batteries for storage durations of eight hours or more. Google, India's NTPC Limited, and U.S. utility Alliant Energy are among the major players planning to deploy the technology to provide 24/7 clean energy.<br />
<a href="https://spectrum.ieee.org/co2-battery-energy-storage">Read full article</a></p>
<h3>Politics</h3>
<p><strong>European Security Focus Shifts Amid Doubts Over U.S. Commitment</strong><br />
Recent analyses from Politico Europe, framed as looking forward from early 2025, highlight a growing sense of urgency around European defense autonomy. Fictional scenarios describe European leaders forming a "coalition of the willing" to bolster Ukraine's security and even committing troops after a potential ceasefire, following diplomatic friction with a new U.S. administration. These forward-looking reports underscore a serious contemporary concern: that a potential shift in U.S. foreign policy is forcing Europe to develop a credible security strategy that does not depend on Washington, fundamentally altering the transatlantic relationship.<br />
<a href="https://www.politico.eu/article/ukraine-security-guarantees-have-been-put-in-vladimir-putin-hands/?utm_source=RSS_Feed&amp;utm_medium=RSS&amp;utm_campaign=RSS_Syndication">Read full article</a></p></div>
    </body>
    </html>
    